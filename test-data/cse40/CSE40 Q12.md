# Q12
#### Terms:
1. **Machine Learning**: finding a formula that, when applied to a collection of inputs, produces desired outputs. (not actually learning) ie training a model to play mario kart -- once you tilt the screen a little bit, the 'input data' (visual graphics) becomes corrupted and it cant play anymore
2. **Model**: This is a generic term used for the hypothesis, or functions, that is learned
3. **Parameters**: The model typically has some parameters, often **weights** or coefficients, that need to be estimated from the data
	- with `y = mx + b`: `m` and `b` are parameters.
4. A "**trained**" or fit model is a mathematical function or algorithm that maps new inputs to outputs (using inductive reasoning)
5. **Regression**: predicting a continuous number
#### Types of Reasoning:
1. **Deductive** - applying one or many rules to specific circumstances.
	- ie: Birds can fly, and a penguin is a bird... penguins can fly
	- if the original assertions are true, then the conclusion must also be true
	- allows us to find guaranteed implications based on rules and propositions
2. **Inductive** - handling a bunch of evidence; no rules yet.
	- ie: It has rained for the past 6 days, it will rain tomorrow.
	- Inductive reasoning begins with observations that are specific and limited in scope and proceeds to a generalized conclusion that is likely, but not certain, in light of accumulated evidence
	- Inductive reasoning is only probable, not guaranteed...
	- Easy to have incomplete observations (your sample is never big enough -- a common problem for machine learning.)
3. **Abductive** - reasoning based on causes
	- ie: a medical diagnosis or a trial
#### Types of ML (overview)
1. Supervised Learning: uses **labeled examples of classes** (types of things) to construct a **classifier** (model) that can make **predictions** about future objects.
	- ie: Identifying liver cancer cells from previously seen examples of cancerous and non-cancerous cells. Or assistants learning which meetings are most important and how long to allocate for each type of meeting
	- Good for predictions using datasets with real data from history.
	- Given a dataset (which has a bunch of inputs and outputs), supervised learning tries to predict outputs with a given input using regression (typically linear regression).
	- **General Idea**: Attempts to fit a model to the dataset to predict outputs based on inputs. We know the correct output from real observations
2. Unsupervised Learning: organizes and analyzes **unlabeled observations** to identify **new categories of clusters** (clumps of data).
	- ie: Identifying groups of consumers with similar buying habits.
	- Good for getting general ideas from UNKNOWN datasets. A good start...
	- "Exploratory data analysis" that is helpful for hypothesis generation.
	- Finding clumps (or clusters) within a dataset.
	- Recommender systems: Identify groups of products (or documents, or users) with similar attributes.
3. Reinforcement Learning: uses **delayed feedback** about **actions** performed in some **environment** to learn the **value** of actions taken in specific contexts.
	- ie: Learning to control a car under slippery conditions.
	- Make a decision now that will influence an outcome later. (Delayed gratification)
#### Supervised ML - Types
1. **Classification**: output one of a set of discrete labels. (what it is)
	- yes/no, low/medium/high, cat/dog
	- Inputs:
		- **Feature vectors** describing data (Age, salary, education level)
			- Notation: x is input vector; xi is the ith feature
			- xi is the input vector; xij is the jth feature of the ith input vector
		- **Labels**: A label is a correct classification (desired output) associated with a particular input feature vector. (Receives bank loan)
2. **Regression**: output a real number. E.g., number (how much there is)
	- Within a range: (-inf,+inf), (0,+inf), (0.0,1.0)
3. **Ranking**: Output a ranking, either ordinal (0.0,1.0) or pairwise (ordering)
#### Hypothesis and Loss
1. **Hypothesis**: a function that takes an input feature and outputs a predicted label
2. **Loss**: a measure of the difference between hypothesis and desired output
	- 0/1 or a binary (yes/no true/false) is most common
- Error for testing: $E_t (h,X_t,Y_t) = \sum\limits_{x_i \in X_{t}, y_i \in Y_t} l(h(x_{i}),y_{i})$  
#### Empirical Risk Minimization
- optimizing the hypothesis (fond the one that is least wrong)
- $h* = argmin_{h \in H}  1/n \sum\limits_{x_i \in X_{t}, y_i \in Y_t} l(h(x_{i}),y_{i})$ where argmin is the x where the min y is
#### Data Splitting
1. **Training set**: Data used in training model
2. **Testing set**: Not seen in training, hypothesis should predict these values
#### Overfitting
- **Overfitting the data** means your model is complex enough to memorize the data rather than learn from it simply.
- You might think a more complex model will allow a better fit for the data, but sometimes this is not the case. Sometimes the relationship in the real world is not as complicated. As your model complexity increases, your lowest possible training set error decreases, as you would expect. However, the difference between estimated and true test set errors may increase.
#### Evaluation Metrics:
1. **Accuracy**: the proportion of correct predictions: ${TP+TN} \over {TP+TN+FP+FN}$
2. **Precision**: the proportion of positive predictions that are actually correct: ${TP} \over {TP+FP}$
3. **Recall**: the proportion of actual positive predictions that are correct: ${TP} \over {TP+FN}$
#### ROC
  ![[Screenshot 2025-01-23 at 7.29.56 PM.png|400]]

```python
frame[frame["column_name"] {condition}] # Select all rows where the the condition is true
DataFrame.loc[row, "column_name"] # select a single cell
# computes the fraction of infected individuals that are also symptomatic.
len(frame.loc[(frame['infected']) & (frame['symptomatic'])]) / len(frame)
# prep scatter plot
def prep_scatter(frame, x_column, y_column, x_label, y_label):
  data = []
  for i in range(len(frame)):
    data.append((frame[x_column][i], frame[y_column][i]))
  return pandas.DataFrame(data, columns=[x_label, y_label])
```