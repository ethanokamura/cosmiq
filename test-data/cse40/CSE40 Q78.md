# Q78 Cheat Sheet

**Learning Techniques:**

- **Eager learning**: linear models, decision trees, neural networks
- **Lazy learning**: nearest neighbors
- **Decision Boundary**: Separates positive/negative regions in feature space
  - Helps us visualize how examples will be classified for the entire feature space
  - Helps us visualize the complexity of the learned model
- **Entropy**: Measures uncertainty in bits: $H(Y) = - \\sum \\limits_y p(Y=y)\\log_2 p(Y=y)$
- **Parameters**: model weights, decision tree splits, etc
- **Hyper-parameters**: regularization, k, etc.

**Linear Models**

- Works when we are trying to predict continuous values
- The goal of learning is to find the best weight vector (best params $\\theta$)
- Used for predicting continuous values and binary classification
- Cast learning as optimization problem
- Optimization: loss function (fit) + regularizer (simplicity)
  - Loss function: measures how well classifier fits training data
  - Regularizer: measures how simple the classifier is
- **Key functions**:
  - Sigmoid: $sigmoid(z) = {1\\over 1+e^{-z}} \\rightarrow \[0,1\]$
  - Linear regression: $y=mx+b$ (linear)
  - Logistic regression: $1\\over{1+e^{-(mx+b)}}$ (curved)
- The weights and bias together are **parameters** of the model (often denoted as $\\theta$)
- The magnitude and sign (negative/positive) of the weights shows importance and direction of influence of features
- **Generalized Linear Models**: $y = h(x) = f(w \\cdot x)$
- **Weight vector**: $w = {w_0,\\dots,w_d}$, a bias term $b$, and with feature vector $x = {1, x_1,\\dots,x_d}$
- **Optimization**: $argmin\_{\\theta} L\_{total}(X,Y,\\theta) = \\sum\\limits\_{x_i}l(f\_\\theta(x_i),y_i) + \\alpha \* R(\\theta)$
- **Regularization**:
  - We can use **distance metrics** (AKA **norms**) to measure the effective size of the weight vector / parameters (Notation: $||w||$ or $||\\theta||$)
  - $L_1$ norm: $||\\theta||\_1 = \\sum_i |\\theta_i| \\rightarrow$ convex, smooth, easy to optimize
  - $L_2$ norm: $||\\theta||\_2 = \\sqrt{\\sum_i \\theta_i^2} \\rightarrow$ encourages sparse weight vectors, convex (not smooth at axis points)
- **Stochastic gradient descent** (SGD) is a simple, yet very efficient, variant of gradient descent used for fitting linear models. Efficient for large datasets, updates weights on small subsets. It chooses performs a gradient over subsets of data points instead of looking at them as a while

**Perceptrons**

- $f(x,w) = sign(w\\cdot x)$
- Inputs are **feature vectors**, each feature has a **weight**, sum is the **activation**, add **bias term**, feature that is always $1$
- activation$*w(x) = \\sum\\limits*{i}w_i\\cdot f_i(x)$ (scalars) $= w \\cdot f(x)$ (vectors) where the result is either positive/negative $\\rightarrow$ output is +/- $1$
- **Learning rule**: Update weights if classification is incorrect: $w = w + y \\cdot f$
  - stopping early is good to avoid overfitting and simple modifications can dramatically improve performance (voting/averaging)
  - For each training instance - classify with current weights ($\\hat y = 1$ if $w\\cdot f(x) \\geq 0$ else $\\hat y = -1$), if correct ($\\hat y = y$), no change!, if wrong, adjust the weight vector by adding or subtracting the feature vector. (subtract if y is -1)
  - ex: perceptron with $w = (1,2,-1)$ and input $(1,1,1)$ where the output was meant to be $-1$, whats the new weight vector? $w = w + y \\cdot f = (1,2,-1) - 1 \\cdot (1,1,1) = (0,1,-2)$
- **Properties**:
  - **Separability**: Can classify data if separable
  - **Convergence**: Stops updating once data is classified correctly

**Naive Bayes**

- Assumes feature independence given the class
- Design Decisions: representing probabilistic relationships for different kinds of features and smoothing (using prior probabilities) to avoid overfitting
- Uses Bayes' Rule for classification: $P(y|x)={P(y)\\prod^n\\limits\_{i=1} P(x_i|y) \\over P(x)}$
- Ex. Digit recognizer - probability that a number is displayed based on which pixels are filled

**Decision Trees**

- Non-linear, interpretable model with high variance
- Good splits create homogeneous subsets
- A good attribute splits the examples into subsets that are ideally "all positive" or "all negative"

**Nearest Neighbors**

- Easy to implement, but can be slow at deployment / classification time and can break down in very high-dimensional spaces
- Stores all training examples, classifies based on closest matches
- **Distance metrics**:
  - Determines the layout of the example space and helps measure similarity between instances
  - $L_1$ (Manhattan)
  - $L_2$ (Euclidean)
  - $L\_\\infty$ (Chebyshev / Max norm)
- **Hyperparameter k**:
  - Determines complexity and how large a neighborhood we should consider
  - Small $k$ → complex model
  - Large $k$ → smoother decision boundary
  - If $k=N$, the entire feature space is one neighborhood
- Epsilon ball NN
  - Instead of using $k$ nearest neighbors, use all examples $x'$ such that $distance(x,x') \\leq \\epsilon$ for some value $\\epsilon$

**Neural Networks**

- Stacked perceptrons with non-linear activations
- Uses back-propagation for learning, forward-propagation for predictions
- Neural networks are made up of **nodes** or **units**, connected by **links**.
- Each link has an associated **weight** and **activation level**.
- Each node has an **input function** (typically summing over weighted inputs), an **activation function**, and an **output**.